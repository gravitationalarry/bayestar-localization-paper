\documentclass{iopart}
\usepackage{iopams}
\usepackage{aas_macros}
\usepackage[colorlinks]{hyperref}
\input{acronyms}

% From http://www.f.kth.se/~ante/latex.php
\setlength{\marginparwidth}{1.2in}
\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\-\oldmarginpar[\raggedleft\footnotesize #1]%
{\raggedright\footnotesize #1}}

\begin{document}

\title[Rapid-response Bayesian sky localization]{Rapid-response Bayesian sky localization for electromagnetic follow-up of gravitational-wave candidates}
\author{Leo Singer and Larry Price}
\address{LIGO Laboratory, California Institute of Technology, Pasadena, CA 91125, USA}
\ead{\mailto{leo.singer@ligo.org}, \mailto{larry.price@ligo.org}}

\begin{abstract}
Timely \acl{EM} follow\nobreakdashes-up of \acl{CBC} events detected by \acl{aLIGO} requires rapidly inferring the sky location from the \ac{GW} observations.  Calculation of the posterior distribution of the sky location and intrinsic source parameters given the \ac{GW} strain takes hours with state\nobreakdashes-of\nobreakdashes-the\nobreakdashes-art \ac{MCMC} parameter estimation codes.  By taking as the measurement not the \ac{GW} strain itself but the amplitude and \acl{TOA} of the putative signal at each detector, and by fixing the intrinsic source parameters, we have constructed a non-\ac{MCMC}, fully deterministic Bayesian parameter estimation algorithm that takes just seconds to produce sky maps of posterior probability.%
\marginpar{Wrong emphasis?  I like Larry's idea of having this paper discuss several different tiers of sky localization with increasing accuracy and latency.}
\end{abstract}

\section{Outline}

\begin{enumerate}
\item Introduction {
	\begin{enumerate}
	\item Background: \acp{GRB}, \acp{CBC}, \acs{LIGO}
	\item Time scales of \acp{GRB}, \acp{CBC}
	\item Current sky localization algorithms and response times
	\end{enumerate}
}
\item Preliminaries {
	\begin{enumerate}
	\item Fisher information, \ac{CRLB}
	\item Matched\nobreakdashes-filter estimator
	\end{enumerate}
}
\item Algorithm {
	\begin{enumerate}
	\item Assumptions
	\item Signal model
	\item Likelihood function
	\item Priors and marginalization
	\item Procedure
	\end{enumerate}
}
\item Results {
	\begin{enumerate}
	\item Injection population
	\item Cumulative fraction vs. confidence level plots
	\item Sky localization accuracy as a function of distance or \ac{SNR}
	\item Speed
	\end{enumerate}
}
\item Discussion {
	\begin{enumerate}
	\item Potential further refinements
	\item What astrophysical targets were accessible before
	\item What new targets are available with the response time of seconds
	\item Lay out timeline of follow\nobreakdashes-up campaign, including different tiers of inference and different types of telescopes
	\end{enumerate}
}
\item Appendices {
	\begin{enumerate}
	\item Code listing?
	\item Any proofs that are needed in the body but would interrupt the text?
	\end{enumerate}
}
\end{enumerate}






\section{New section, add a new name to this}

A CBC will emit a GW. What we detect will be the data, $x(t)$ which is a function of time. This data will be a combination of the signal emitted from the CBC< $h(t)$, and the noise our detector picks up in addition to the signal, $n(t)$. We assume we have additive, zero mean, wide source stationary, Gaussian measurement noise $n(t)$. This means that noise is only added to what passes through the channel, the mean of this noise is zero, the noise does not vary in time, and the noise is drawn from a Gaussian distribution. 

Our goal here is to first determine the likelihood.

Our detector data is given by $x(t)$. This can be described in the frequency domain as $\tilde{x}(f) = \tilde{h}(f) + \tilde{n}(f)$ where $\tilde{h}(f)$ is our signal and $\tilde{n}(f)$ is the noise. We have noise, $E[n(t_1)n(t_2)]$ which depends only on $t_1 - t_2$. The Fourier transform of the noise gives us this: $E[\tilde{n}(f)^*\tilde{n}(f)] = \delta (f_1 - f_2) s(f_1)$ where $s(f)$ is the power spectral density for the noise. The power spectral density gives us information about the energy of the present frequencies. The delta function is only non-zero when the input is zero, so in this case we will only get a nonzero value for $\delta (f_1 - f_2) s(f_1)$ when $f_1 = f_2$. 

To determine the power spectral density (PSD) for the real signal $y(t)$ we first take the Fourier transform of our real signal to get:

\begin{equation}
	\tilde{y}(f) = \int_{-\infty}^{\infty}y(t)e^{-2\pi ift}dt
\end{equation}

Then we get the two sided PSD from the definition of PSD.
 
\begin{equation}
	R_y(f) = |\tilde{y}(f)|^2
\end{equation}

Then we get the single sided PSD with a conversion,

\begin{equation}
	S_y(f) = |\tilde{y}(f)|^2 + |\tilde{y}(-f)|^2
\end{equation}

We can decompose our signal into two orthogonal bases with

\begin{equation}
	\tilde{h}(f) = a\tilde{h}_0(f) + b\tilde{h}_{\pi/2}(f)
\end{equation}

Defining
\begin{eqnarray}
	\tilde{h}_0(f) & = & -i \tilde{h}_{\pi/2}(f) \mbox{ for } f > 0 \\
	\tilde{h}_0(-f) & = & i \tilde{h}_{\pi/2}(-f) \mbox{ for } f < 0
\end{eqnarray}

This ends up resulting in
\begin{equation}
	\tilde{h}(f) = (a + bi)\tilde{h}_0(f)
\end{equation}

Next we'll set $\tilde{u}(f) = \tilde{h}_0(f)$. 

We can rewrite our signal in polar form to get the following.
\begin{eqnarray}
	\tilde{h}(f) & = & (a + bi) \tilde{u}(f) e^{-2\pi ift_0} \\
	& = & Ce^{i \phi}\tilde{u}(f)e^{-2\pi ift_0} \\
	& = & Ce^{i(\phi - 2\pi ft_0)}\tilde{u}(f)
\end{eqnarray}

This gives us a definition of $\tilde{h}(f)$ to be used in our likelihood and allows us to update our definition of $\tilde{x}(f)$

\begin{eqnarray}
	\tilde{x}(f) & = & Ce^{i(\phi - 2\pi ft_0)}\tilde{u}(f) + \tilde{n}(f) \mbox{ for } f > 0 \\
	\tilde{x}(f) & = & \tilde{x}^*(f) \mbox{ for } f < 0
\end{eqnarray}

We can now obtain our likelihood function from the definition of a univariate gaussian for a continuous signal ${\bf{x}}(f)$,
\begin{equation}
	f({\bf{x}}) = \frac{1}{\sqrt{\det(2\pi \bf{\Sigma})}}\exp(-\frac{1}{2}(\bf{x}-\bf{u})^T\Sigma^{-1}(\bf{x}-\bf{\mu}))
\end{equation}
Expressing this in frequency space,
\begin{equation}
	f({\bf{\tilde{x}}}(f)) \propto \exp[-\frac{1}{2}\int\int( {\bf{x}}(f)-{\bf{\mu}}(f))^*C(f,f')(\tilde{x}(f')-\mu(f'))]dfdf'
\end{equation}
Where $C(f,f')$ represents the covariance. Now we can determine the log of our likelihood function.

\begin{equation}
	\ln(L(\tilde{x}; C, \phi, t_0)) \sim -\frac{1}{2}\int_0 ^\infty \frac{|\tilde{x}(f) - \tilde{h}(f; C, \phi, t_0)|^2}{S_n(f)}df
\end{equation}

There will be a time delay between the time of coalescence and the time the signal arrives at our detector. We'll see what this means we should expect by introducing a time delay in frequency space. Our real signal data is given by $y(t)$, so we can introduce a delay by changing the time, $y(t - t_0) = z(t)$ where $t$ is the time of arrival and $t_0$ the time of coalescence. So $z(t)$ now contains our time delay. We take the Fourier transform of $z(t)$ and are left with

\begin{equation}
	\tilde{z}(f) = \int^{\infty}_{-\infty}y(t-t_0)e^{-2\pi ift} dt
\end{equation}

Introducing a change of variables from $t$ to $t' = t - t_0$ gives us
\begin{eqnarray}
	\tilde{z}(f) & = & e^{-2\pi ift_0} \int_{-\infty}^{\infty}y(t')e^{-2\pi ift'} dt' \\
	& = & e^{-2\pi ift_0} \tilde{y}(f)
\end{eqnarray}

This means that a time delay introduced a phase shift in frequency. 

Now we can develop the Fisher information matrix. This will tell us how our variables affect each other. The Fisher information matrix is defined as 
\begin{equation}
\mathcal{I}_{ij} \equiv E[-\frac{\partial^2 \ln L}{\partial \theta_i \partial \theta_j}]
\end{equation}
 for $L(\theta_1, \theta_2, ...)$.

So if we take our likelihood we'll end up with this,
\begin{eqnarray}
	\frac{\partial \ln L}{\partial \theta_i} & = & -\frac{1}{2} \int_0 ^\infty \frac{2}{s_n(f)}Re\{[\frac{\partial}{\partial \theta_i} (\tilde{x} - \tilde{h})][\tilde{x} - \tilde{h}]\}df \\
	& = & \int_0 ^\infty Re[(\frac{\partial \tilde{h}}{\partial \theta_i})^*(\tilde{x} - \tilde{h})]\frac{df}{s(f)} \\
	\frac{\partial^2 \ln L}{\partial \theta_i \partial \theta_j} & = & \int_0 ^\infty Re[(\frac{\partial^2 \tilde{h}}{\partial \theta_i \partial \theta_j})^*(\tilde{x} - \tilde{h})\frac{df}{s(f)} + \int_0 ^\infty Re[(\frac{\partial \tilde{h}}{\partial \theta_i})^*\frac{\partial \tilde{h}}{\partial \theta_j}]\frac{df}{s(f)}] \\
\end{eqnarray}

Apply this to the definition of the Fisher information matrix,
\begin{eqnarray}
	\mathcal{I}_{ij} & = & E[-\int_0^\infty (\frac{\partial ^2 \tilde{h}}{\partial \theta_i \partial \theta_j})^*(\tilde{x} - \tilde{h})\frac{df}{s(f)} + \int_0 ^ \infty Re[(\frac{\partial \tilde{h}}{\partial \theta_i})^*\frac{\partial \tilde{h}}{\partial \theta _j}]\frac{df}{s(f)}] \\
	& = & \int^\infty _0 Re[(\frac{\partial \tilde{h}}{\partial \theta_i})^* \frac{\partial \tilde{h}}{\partial \theta _j}]\frac{df}{s(f)}
\end{eqnarray}

Putting this into a matrix and defining $M_k = \int_0^\infty \tilde{u}(f)^* u(f) f\frac{df}{s(f)}$ and $N_k = \frac{M_k}{M_0}$ gives us
\[
\mathcal{I} =
\left( {\begin{array}{ccc}
 M_0 & 0 & 0 \\
 0 & C^2M_0 & -2\pi C^2M_1 \\
 0 & -2\pi C^2M_1 & 4\pi^2C^2M_2
 \end{array} } \right)
\]

Now we will perform three changes of variables to diagonalize this matrix.

The first change of variables is from $C$ to $\rho = \sqrt{M_0}C$. 
\[
\mathcal{I} =
\left( {\begin{array}{ccc}
 1 & 0 & 0 \\
 0 & \rho^2 & -2\pi\rho^2 N_1 \\
 0 & -2\pi\rho^2 N_1 & 4\pi^2 \rho^2 N_2
 \end{array} } \right)
\]

The second from $t$ to $\phi_t = t2\pi \sqrt{N_2}$ gives us
\[
\mathcal{I} =
\left( {\begin{array}{ccc}
 1 & 0 & 0 \\
 0 & \rho^2 & -\rho^2\frac{N_1}{\sqrt{N_2}} \\
 0 & -\rho^2\frac{N_1}{\sqrt{N_2}} & \rho^2
 \end{array} } \right)
\]

The third introduces two new variables, $\phi_s = \frac{1}{\sqrt{2}}(\phi + \phi_t)$ and $\phi_d = \frac{1}{\sqrt{2}}(\phi - \phi_t)$. This results in this matrix,
\[
\mathcal{I} =
\left( {\begin{array}{ccc}
 1 & 0 & 0 \\
 0 & (1 - \frac{N_1}{\sqrt{N_2}})\rho^2 & 0 \\
 0 & 0 & (1 + \frac{N_1}{\sqrt{N_2}})\rho^2
 \end{array} } \right)
\]

Now we'll do a final change of variables to make the phases have the same variance. We let $\alpha_s = \phi_s \sqrt{1 - \frac{N_1}{\sqrt{N_2}}}$ and $\alpha_d = \phi_d \sqrt{1 - \frac{N_1}{\sqrt{N_2}}}$ which gives us the matrix
\[
\mathcal{I} =
\left( {\begin{array}{ccc}
 1 & 0 & 0 \\
 0 & \rho^2 & 0 \\
 0 & 0 & \rho^2
 \end{array} } \right)
\]












\section{Measurement uncertainty}

\cite{fairhurst:2009} estimated the uncertainty in the matched-filter measurement of the \ac{TOA} of a \ac{GW} signal by computing the scalar Fisher information.  We extend this result by computing the Fisher information matrix describing the uncertainties in the joint estimation of the signal amplitude and \ac{TOA}.%
%
\marginpar{This might be too much mathematical detail.  All we need to do is show that the $\rho_A\rho_A$ and $\rho_B\rho_B$ terms are unity and that the off-diagonal terms vanish.  If possible, we should cite and use Fairhurst's expression for $\mathcal{I}_{t_0,t_0}$ without re-deriving it.}

When a \ac{CBC} occurs, a detector's strain observation may be described by a linear combination of two orthogonal \ac{GW} quadratures, $a(t)$ and $b(t)$, and additive, zero\nobreakdashes-mean, \acl{WSS}, Gaussian measurement noise $n(t)$, with power spectral density $S(f)$.  Introducing the unknown, real, quadrature amplitudes, $A$ and $B$, and the unknown \ac{TOA}, $t_0$, we can write
%
\begin{equation}\label{eq:xoft}
	x(t) = A a(t - t_0) + B b(t - t_0) + n(t).
\end{equation}
%
Transformation of \Eref{eq:xoft} to the frequency domain converts the time delay by $t_0$ to a complex phase,
%
\begin{equation}\label{eq:xoff}
	\tilde{x}(f) = \left(A \tilde{a}(f) + B \tilde{b}(f)\right)e^{-2 \pi i f t_0} + \tilde{n}(f).
\end{equation}
%
The Fisher information matrix for a measurement $\mathbf{x}$ described by the unknown parameters $\boldsymbol{\theta}$ may be written as
%
\begin{equation}
	\mathcal{I}_{jk} = \mathrm{E} \, \left[
		-\frac{\partial^2 \log
			\mathcal{L}(\mathbf{x}; \boldsymbol{\theta})}
			{\partial \theta_j \theta_k}
	\right].
\end{equation}
%
First, we write the likelihood of the data $\tilde{x}(f)$ given the parameters $(A, B, t_0$):
%
\begin{equation}\label{eq:trigger-likelihood}
	\fl\mathcal{L}(x; A, B, t_0) = p(x | A, B, t_0)
		\propto \exp \left[
		- \frac{1}{2} \int_{-\infty}^\infty \frac{\left|\tilde{x}(f)
			- \left(A \tilde{a}(f)
			- B \tilde{b}(f)\right) e^{-2 \pi i f t_0}\right|^2}{S(f)} \, \mathrm{d}f
	\right].
\end{equation}
%
The normalization has been dropped because the Fisher matrix elements depend only on derivatives of the log\nobreakdashes-likelihood function and any factor that is independent of the parameters makes no contribution.%
%
\marginpar{Consider using discrete time to avoid the fiction of an infinite-dimensional multivariate Gaussian process.}
%
From hereon, unless otherwise specified the limits of integration are always $(-\infty, \infty)$ and will be dropped.  Expanding the integrand, we can write the log\nobreakdashes-likelihood function up to an additive constant as
%
\begin{eqnarray}\label{eq:trigger-likelihood}
	\log \mathcal{L}(x; A, B, t_0) \sim
	&- \frac{1}{2} \int \frac{|\tilde{x}(f)|^2}{S(f)} \mathrm{d}f \\
	&+ A \, \mathrm{Re} \int \frac{\tilde{a}^*(f) \tilde{x}(f) e^{2 \pi i f t_0}}{S(f)} \mathrm{d}f \nonumber\\
	&+ B \, \mathrm{Re} \int \frac{\tilde{b}^*(f) \tilde{x}(f) e^{2 \pi i f t_0}}{S(f)} \mathrm{d}f\nonumber\\
	&+ A B \, \mathrm{Re} \int \frac{\tilde{a}^*(f) \tilde{b}(f)}{S(f)} \mathrm{d}f \nonumber\\
	&- \frac{1}{2} A^2 \int \frac{|\tilde{a}(f)|^2}{S(f)} \mathrm{d}f
	- \frac{1}{2} B^2 \int \frac{|\tilde{b}(f)|^2}{S(f)} \mathrm{d}f.
\end{eqnarray}
%
We assume that $\tilde{a}(f)$ and $\tilde{b}(f)$ are orthogonal and have the same norm,
%
\begin{equation}
	\int \frac{\tilde{a}^*(f) \tilde{b}(f)}{S(f)} \mathrm{d}f = 0,
	\int \frac{|\tilde{a}(f)|^2}{S(f)} \mathrm{d}f =
	\int \frac{|\tilde{b}(f)|^2}{S(f)} \mathrm{d}f =
	\sigma^2.
\end{equation}
%
After we apply these substitutions, and drop the $|\tilde{x}(f)|^2$ term that is independent of $A$, $B$, or $t_0$, we can write the log\nobreakdashes-likelihood function as
%
\begin{eqnarray}\label{eq:trigger-likelihood-simplified}
	\log \mathcal{L}(x; A, B, t_0) \sim
	& A \, \mathrm{Re} \int \frac{\tilde{a}^*(f) \tilde{x}(f) e^{2 \pi i f t_0}}{S(f)} \mathrm{d}f 
	&+ B \, \mathrm{Re} \int \frac{\tilde{b}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} }{S(f)} \mathrm{d}f\nonumber\\
	&- \frac{1}{2} A^2 \sigma^2 - \frac{1}{2} B^2 \sigma^2.
\end{eqnarray}
%
The necessary partial derivatives are
%
\begin{eqnarray*}
	\frac{\partial^2 \log \mathcal{L}}{\partial A \partial B} &= 0 \\
	\frac{\partial^2 \log \mathcal{L}}{\partial A \partial t_0} &=
	2 \pi i \int \frac{\left(\tilde{a}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} - \tilde{a}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f \mathrm{d}f \\
	\frac{\partial^2 \log \mathcal{L}}{\partial B \partial t_0} &=
	2 \pi i \int \frac{\left(\tilde{b}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} - \tilde{b}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f \mathrm{d}f \\
	\frac{\partial^2 \log \mathcal{L}}{\partial A^2} &=
	\frac{\partial^2 \log \mathcal{L}}{\partial B^2} = - \sigma^2 \\
	\frac{\partial^2 \log \mathcal{L}}{\partial {t_0}^2} &=
	2 \pi i A \int \frac{\left(\tilde{a}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} - \tilde{a}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f \mathrm{d}f \\
	&+ 2 \pi i B \int \frac{\left(\tilde{b}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} - \tilde{b}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f \mathrm{d}f \\
	&- (2 \pi)^2 A \int \frac{\left(\tilde{a}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} + \tilde{a}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f^2 \mathrm{d}f \\
	&- (2 \pi)^2 B \int \frac{\left(\tilde{b}^*(f) \tilde{x}(f) e^{2 \pi i f t_0} + \tilde{b}(f) \tilde{x}^*(f) e^{-2 \pi i f t_0}\right)}{S(f)} f^2 \mathrm{d}f.
\end{eqnarray*}
%
Finally, taking the expectation values of the partial derivatives, we find
%
\begin{eqnarray*}
	\mathcal{I}_{A,B} &= \mathcal{I}_{A,t_0} = \mathcal{I}_{B,t_0} = 0 \\
	\mathcal{I}_{A,A} &= \mathcal{I}_{B,B} = \sigma^2 \\
	\mathcal{I}_{t_0,t_0} &=
	- 2 \pi i A^2 \int \frac{|\tilde{a}(f)|^2}{S(f)} f\mathrm{d}f
	- 2 \pi i B^2 \int \frac{|\tilde{B}(f)|^2}{S(f)} f\mathrm{d}f \\
	&+ (2 \pi)^2 \left(A^2 \int \frac{|\tilde{a}(f)|^2}{S(f)} f^2\mathrm{d}f +
	B^2 \int \frac{|\tilde{b}(f)|^2}{S(f)} f\mathrm{d}f \right) \\
	&+ (2\pi)^2 2 A B \, \mathrm{Re} \int \frac{\tilde{a}^*(f)\tilde{b}(f)}{S(f)} f^2\mathrm{d}f.
\end{eqnarray*}
%
$\mathcal{I}_{A,t_0}$, $\mathcal{I}_{B,t_0}$, and the first two terms of $\mathcal{I}_{t_0,t_0}$ vanish because the integrands $|\tilde{a}(f)|^2 f / S(f)$ and $|\tilde{b}(f)|^2 f / S(f)$ are odd about $f = 0$.  We assume that $\tilde{a}(f)$ and $\tilde{b}(f)$ are orthogonal with respect to $\emph{any}$ real weight, including both $S(f)$ and $S(f) / f^2$, so the last term in $\mathcal{I}_{t_0,t_0}$ vanishes as well.  Further,%
%
\marginpar{This is an awkward place to make these substitutions.  Also, they are poorly motivated.  Here's what this substitution actually does: the matched\nobreakdashes-filter output has an expected value of $A \sigma = \rho_A$.}
%
we make the substituions
%
\begin{eqnarray*}
	\rho_A &= A \sigma \\
	\rho_B &= B \sigma \\
	f_\mathrm{rms} &= \left[ \int \frac{|\tilde{a}(f)|^2}{S(f)} f^2\mathrm{d}f \right] ^ {1/2} \left[\int \frac{|\tilde{a}(f)|^2}{S(f)} \mathrm{d}f \right] ^ {-1/2} \\
	&=  \left[ \int \frac{|\tilde{b}(f)|^2}{S(f)} f^2\mathrm{d}f \right] ^ {1/2} \left[\int \frac{|\tilde{b}(f)|^2}{S(f)} \mathrm{d}f \right] ^ {-1/2}.
\end{eqnarray*}
%
Then, we have
%
\begin{eqnarray*}
	\mathcal{I}_{\rho_A,\rho_B} &= \mathcal{I}_{\rho_A,t_0} = \mathcal{I}_{\rho_B,t_0} = 0 \\
	\mathcal{I}_{\rho_A,\rho_A} &= \mathcal{I}_{\rho_B,\rho_B} = 1 \\
	\mathcal{I}_{t_0,t_0} &= (2 \pi f_\mathrm{rms})^2 ({\rho_A}^2 + {\rho_B}^2).
\end{eqnarray*}
%
The Cram\'{e}r-Rao inequality says that the inverse of the Fisher information matrix is a lower bound on the covariance of any unbiased estimator.  The Fisher matrix for this estimation problem has been shown to be diagonal, so we can write
%
\begin{eqnarray}\label{eq:cramer-rao}
	\mathrm{var}\, (\hat{\rho}_B) &\geq {\mathcal{I}_{\rho_A,\rho_A}}^{-1} = 1 \\
	\mathrm{var}\, (\hat{\rho}_B) &\geq {\mathcal{I}_{\rho_B,\rho_B}}^{-1} = 1 \\
	\mathrm{var}\, (\hat{t}_0) &\geq {\mathcal{I}_{t_0,t_0}}^{-1} = (2 \pi f_\mathrm{rms} \sqrt{{\rho_A}^2 + {\rho_B}^2})^{-2}.
\end{eqnarray}

\section{Posterior distribution}

Because the \ac{CRLB} in \Eref{eq:cramer-rao} is diagonal, joint estimators of $(\rho_A, \rho_B, t_0)$ may exist for which the error in the estimation of the individual parameters is uncoupled up to second order.  If the detector's noise is Gaussian, then the outputs of matched filters for $a(t)$ and $b(t)$ will themselves be Gaussian.  This encourages us to make the approximation that the errors in $(\rho_A, \rho_B, t_0)$ by a matched\nobreakdashes-filter estimator are independent and Gaussian with variance equal to the \ac{CRLB}.  A wrinkle is that $\mathcal{I}_{t_0,t_0}$ depends on the true values of $\rho_A$ and $\rho_B$.  If we make the further leap of evaluating the \ac{CRLB} \emph{at the value of the estimators}, we can write
%
\begin{eqnarray}
\hat{\rho}_A - \rho_A \sim \mathcal{N}\, [0, 1] \\
\hat{\rho}_B - \rho_B \sim \mathcal{N}\, [0, 1] \\
\hat{t}_0 - t_0 \sim \mathcal{N} \left[0, \frac{1}{2 \pi f_\mathrm{rms} \sqrt{{\hat{\rho}_A}^2 + {\hat{\rho}_B}^2}}\right].
\end{eqnarray}

\section{Equations that need to be organized}

\begin{equation}
	u = \cos \iota
\end{equation}

\begin{equation}
	\mathbf{G} =
	\left(
		\begin{array}{cccc}
			F_+^1 D_1^1 & F_+^2 D_1^2 & \cdots & F_+^N D_1^N \\
			F_\times^1 D_1^1 & F_\times^2 D_1^2 & \cdots & F_\times^N D_1^N
		\end{array}
	\right)
\end{equation}

\begin{equation}
	\mathbf{H} = \mathbf{G}\mathbf{G}^\mathsf{T} =
	\left(
		\begin{array}{cc}
			\sum \left(F_+^i D_1^i\right)^2 & \sum \left(F_+^i D_1^i\right)\left(F_\times^i D_1^i\right) \\
			\sum \left(F_+^i D_1^i\right)\left(F_\times^i D_1^i\right) & \sum \left(F_\times^i D_1^i\right)^2
		\end{array}
	\right)
\end{equation}

\begin{equation}
	\mathbf{R} =
	\left(
		\begin{array}{cc}
			\cos \phi & \sin \phi \\
			-\sin \phi & \cos \phi
		\end{array}
	\right)
	\left(
		\begin{array}{cc}
			\frac{1}{2} (1 + u^2) & 0 \\
			0 & u
		\end{array}
	\right)
	\left(
		\begin{array}{cc}
			\cos \psi & \sin \psi \\
			-\sin \psi & \cos \psi
		\end{array}
	\right) \mathbf{G}
\end{equation}

\begin{equation}
	p = \Tr \mathbf{R}^\mathsf{T} \mathbf{R}
	= \frac{1}{8} \left\{
		\left(u^4 + 6 u^2 + 1\right) \left(H_{11} + H_{22}\right) + (1 - u^2)^2
		\left[ \left( H_{11} - H_{22} \right) \cos 2\psi + 2 H_{12} \sin 2\psi \right]
	\right\}
\end{equation}

\begin{equation}\fl
	q = \sqrt{(ab - cd) (u + u^3) + \frac{1}{8} \left\{ (a^2 + b^2 + c^2 + d^2)(u^4 + 6u^2 + 1) + (1 - u^2)^2 \left[ (a^2 - b^2 - c^2 + d^2) \cos 2\psi + 2(ac + bd) \sin 2\psi \right] \right\}}
\end{equation}

\ack Source code for \ac{BAYESTAR} is available on the \acs{LIGO} \acl{DASWG} web site at \url{http://www.lsc-group.phys.uwm.edu/daswg/projects/bayestar.html}.

Some of the results in this paper have been derived using HEALPix \cite{healpix}.

\acs{LIGO} was constructed by the California Institute of Technology and Massachusetts Institute of Technology with funding from the \ac{NSF} and operates under cooperative agreement PHY\nobreakdashes-0107417.  Some results were produced on the NEMO computing cluster operated by the Center for Gravitation and Cosmology at University of Wisconsin\nobreakdashes--Milwaukee under \ac{NSF} Grants PHY\nobreakdashes-0923409 and PHY\nobreakdashes-0600953.  This research is supported by the \ac{NSF} through a Graduate Research Fellowship to L.S.  This paper has \acs{LIGO} Document Number \acs{LIGO}\nobreakdashes-PXXXXXXX\nobreakdashes-vX.


\section*{References}
\bibliographystyle{iopart-num}
\bibliography{apj-jour,telescope}

\end{document}
