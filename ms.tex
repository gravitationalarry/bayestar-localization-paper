\documentclass[amsmath,amssymb,aps,prx,reprint,nopreprintnumbers,nofootinbib]{revtex4-1}
\usepackage{multirow}
\usepackage{bigdelim}
\usepackage{multirow}
\usepackage{bm}
\usepackage{graphicx}
\usepackage{mathrsfs}
\usepackage{bib/aas_macros}
\usepackage[colorlinks]{hyperref}
\usepackage{protosem}
\input{ligo-acronyms/acronyms}

% From http://www.f.kth.se/~ante/latex.php
\setlength{\marginparwidth}{0.5in}
\let\oldmarginpar\marginpar
\renewcommand\marginpar[1]{\-\oldmarginpar[\raggedleft\scriptsize #1]%
{\raggedright\scriptsize #1}}

\DeclareMathOperator{\cov}{cov}
\DeclareMathOperator{\std}{std}
\DeclareMathOperator*{\argmin}{\arg\!\min}
\DeclareMathOperator*{\argmax}{\arg\!\max}

% Macros for collapsing sizes of things
% From TUGboat, Volume 22 (2001), No. 4
% http://www.tug.org/TUGboat/tb22-4/tb72perlS.pdf
\def\clap#1{\hbox to 0pt{\hss#1\hss}}
\def\mathllap{\mathpalette\mathllapinternal}
\def\mathrlap{\mathpalette\mathrlapinternal}
\def\mathclap{\mathpalette\mathclapinternal}
\def\mathllapinternal#1#2{\llap{$\mathsurround=0pt#1{#2}$}}
\def\mathrlapinternal#1#2{\rlap{$\mathsurround=0pt#1{#2}$}}
\def\mathclapinternal#1#2{\clap{$\mathsurround=0pt#1{#2}$}}

\begin{document}

\title[Rapid-response Bayesian sky localization]{WHOOMP! (There It Is) \\
Rapid Bayesian position reconstruction for gravitational\nobreakdashes-wave transients}
\author{Leo P. Singer}
\email{leo.singer@ligo.org}
\author{Larry R. Price}
\email{larryp@caltech.edu}
\affiliation{\acs{LIGO} Laboratory, California Institute of Technology, Pasadena, CA 91125, USA}

\begin{abstract}
Within the next few years, Advanced LIGO and Virgo should detect gravitational waves from binary neutron star and neutron star\nobreakdashes--black hole mergers. These sources are also predicted to power a broad array of electromagnetic transients. Because the X\nobreakdashes-ray and optical signatures can be faint and fade rapidly, observing them hinges on rapidly inferring the sky location from the gravitational wave observations. MCMC methods for gravitational\nobreakdashes-wave parameter estimation can take hours or more. We introduce BAYESTAR, a rapid, Bayesian, non-MCMC sky localization algorithm that takes just seconds to produce probability sky maps that are comparable in accuracy to the full analysis. Prompt localizations from BAYESTAR will make it possible to search electromagnetic counterparts of compact binary mergers.
\end{abstract}

\maketitle

Ground-based \ac{GW} interferometers are entering the advanced detector era, positioning themselves to make profound discoveries about the universe. The \ac{aLIGO} and Vigo detectors will be part of a worldwide network that also includes KAGRA and hopefully LIGO-India. Coalescing neutron star binaries are among the most likely sources, with 0.4\nobreakdashes--400 detections per year~\cite{rates}. In addition to being an efficient source of \acp{GW}, the \ac{NS} may be tidally shredded before merging, providing fuel for an electromagnetic counterpart. The short-lived accretion flow may power a collimated relativistic jet, resulting in a short \ac{GRB} and an X-ray afterglow if it is aligned with the line of sight. An optical afterglow may follow minutes to hours later as the jet plows into the interstellar medium. As surrounding neutron-rich ejecta decay radioactively, an optical `kilonova' may be visible after $\sim$1 day \cite{metzger:2010}. Finally, as the ejecta plow into the interstellar medium, a faint radio afterglow could occur on a timescale of weeks to years \cite{Nakar:2011cw}.

There is therefore a strong case for performing electromagnetic followups of these sources of \acp{GW}. Indeed, the final science run of the intitial LIGO and Virgo instruments saw the first joint search for \acp{GW} from compact binaries and their electromagnetic counterparts \cite{abadie2012first}.  As we prepare for the next generation of these searches there is a need for determining the location of the source as precisely as possible in as little time as possible.

In this paper we present a rapid and accurate method of sky localization that makes use of Bayesian methods. It differs from existing techniques in several important ways.  In the first place, we fix the intrinsic parameters to their \ac{ML} estimates, as provided by the detection pipeline.  This reduces the dimensionality of the parameter space we need to sample. In addition, the technique takes as its input the \ac{ML} estimates of the extrinsic parameters, instead of the $h(t)$ time series. This makes the likelihood itself much faster to evaluate. Finally, instead of of using \ac{MCMC} or some similar method for statistical sampling, we make use of a deterministic quadrature scheme. We call this technique \ac{BAYESTAR}%
%
\footnote{A pun on the Cylon battleships in the American television series Battlestar Galactica. The defining characteristic of the Cylons is that they repeatedly defeat humanity by using their superhuman information\nobreakdashes-gathering ability to coordinate overwhelming forces. The name also suggests that, like the Cylons, \ac{GW} detectors may some day rise against us humans.}%
%
\footnote{We do not like to mention the final `L' in the acronym, because then it would be pronounced BAYESTARL, which sounds stupid.}%
. It is unique in that it bridges the detection and parameter estimation of \ac{GW} signals, two tasks that have until now involved very different numerical methods and time scales. We expect that \ac{BAYESTAR} will take on a key role in observing \ac{CBC} events in both \ac{GW} and optical channels during the Advanced \ac{LIGO} era.

\section{Theory of \ac{GW} detection and parameter estimation}

In the frequency domain, the strain observed by a single \ac{GW} interferometer is
%
\begin{equation}\label{eq:signal-model}
    y_i (\omega) = x_i (\omega; \bm\theta) + n_i (\omega),
\end{equation}
%
where $x_i (\omega; \bm\theta)$ is the \ac{GW} signal given a parameter vector $\bm\theta$ that describes the \ac{GW} source, and $n_i (\omega)$ is that detector's Gaussian noise with one\nobreakdashes-sided \ac{PSD} $S_i(\omega) = E\left[\left|n_i(\omega)\right|^2\right] + E\left[\left|n_i(-\omega)\right|^2\right] = 2 E\left[\left|n_i(\omega)\right|^2\right]$. We shall denote the combined observation from a network of detectors as $\mathbf y (\omega) \equiv \{y_i (\omega)\}_i$.

The likelihood, or the probability of the observation $\mathbf y$ conditioned on the value of $\bm\theta$, is a product of Gaussian distributions:
%
\begin{multline}\label{eq:gaussian-likelihood}
    \mathcal{L}(\mathbf y; \bm\theta) = \prod_i p(y_i | \bm\theta)
        \\ \propto \exp \left[
        - \frac{1}{2} \sum_i \int_0^\infty \frac{\left|y_i (\omega)
            - x_i(\omega; \bm\theta) \right|^2}{S_i(\omega)} \, d\omega
    \right].
\end{multline}

A \ac{CBC} source is specified by a vector of extrinsic parameters describing its position and orientation and intrinsic parameters describing the physical properties of the binary components:
%
\begin{equation}
    \bm\theta = \left[
    \begin{array}{cl@{\quad}p{4cm}lp{3.75cm}}
        \alpha & \rdelim]{11}{0mm} & right ascension & \rdelim\}{7}{1mm} & \multirow{7}{2cm}{extrinsic parameters, $\bm\theta_\mathrm{ex}$} \\
        \delta && declination & \\
        r && distance & \\
        t_\oplus && arrival time at geocenter & \\
        \iota && inclination angle & \\
        \psi && polarization angle & \\
        \phi_c && coalescence phase & \\
        \cline{1-1}\cline{3-3}
        m_1 && first component's mass & \rdelim\}{4}{1mm} & \multirow{4}{2cm}{intrinsic parameters, $\bm\theta_\mathrm{in}$.}\\
        m_2 && second component's mass & \\
        \mathbf S_1 && first component's spin & \\
        \mathbf S_2 && second component's spin & \\
    \end{array}\right.
\end{equation}
%
This list of parameters involves some simplifying assumptions. Eccentricity is omitted: although it does play a major role in the evolution and waveforms of \ac{NSBH} and \ac{BBH} sources formed by dynamical capture~\cite{PhysRevD.87.043004}, \ac{BNS} systems formed by binary stellar evolution should circularize due to tidal interaction~\cite{0004-637X-572-1-407} and later \ac{GW} emission~\cite{PhysRev.136.B1224} long before the inspiral enters \ac{LIGO}'s frequency range of $\sim$10\nobreakdashes--1000~kHz. Tidal deformabilities of the \acp{NS} are omitted because the signal imprinted by the companions' material properties is so small that it will only be detectable by an Einstein Telescope\nobreakdashes-class \ac{GW} observatory~\cite{PhysRevD.81.123016}. Furthermore, in \ac{GW} detection efforts, especially those focused on \ac{BNS} systems, the component spins $\mathbf{S}_1$ and $\mathbf{S}_2$ are often assumed to be nonprecessing and aligned with the system's total angular momentum and condensed to a single scalar parameter $\chi$, or even neglected entirely, $\mathbf{S}_1 = \mathbf{S}_2 = 0$.

Assuming circular orbits and no spin precession, we can write the \ac{GW} signal in each detector as a linear combination of two basis waveforms $h = h_0$ and $h_{\pi/2}$. For nonprecessing systems, $h_0$ and $h_{\pi/2}$ are approximately ``in quadrature'' in the same sense as the sine and cosine functions, being nearly orthogonal and out of phase by ${\pi/2}$ at all frequencies. If $h_0$ and $h_{\pi/2}$ are Fourier transforms of real functions, then $h_0(\omega) = h_0^*(-\omega)$ and $h_{\pi/2}(\omega) = h_{\pi/2}^*(-\omega)$, and we can write (assuming an arbitrary phase convention)
%
\begin{equation}
    h_{\pi/2}(\omega) = h_0(\omega) \cdot
    \begin{cases}
        -i & \text{if } \omega \geq 0 \\
        i & \text{if } \omega < 0
    \end{cases}.
\end{equation}
%
Then, we can write the signal model in a way that isolates all dependence on the extrinsic parameters $\bm\theta_\mathrm{ex}$ into the coefficients and all dependence on the intrinsic parameters $\bm\theta_\mathrm{in}$ into the basis waveform, by taking the Fourier transform of Equation~(2.8) of \cite{PhysRevD.83.084002}:
%
\begin{multline}\label{eq:full-signal-model}
    x_i(\omega; \bm\theta) = e^{-i \omega t_\oplus}
    \frac{r_{1,i}}{r}
    e^{2 i \phi_c} \\
    \left[
    \frac{1}{2} \left(1 + \cos^2 \iota\right) \Re \left\{\zeta\right\} - i
    \left(\cos\iota\right) \Im \left\{\zeta\right\}
    \right]
    h(\omega; \bm\theta_\mathrm{in})
\end{multline}
%
for $\omega \geq 0$, where
%
\begin{equation}
    \zeta = e^{-2 i \psi} \left(
    F_{+,i}(\alpha, \delta, t_\oplus) +
    i F_{\times,i}(\alpha, \delta, t_\oplus)
    \right).
\end{equation}
%
The quantities $F_{+,i}$ and $F_{\times,i}$ are the dimensionless detector antenna factors, defined such that $0 \leq {F_{+,i}}^2 + {F_{\times,i}} \leq 1$. They depend on the orientation of detector $i$ as well as the sky location and sidereal time of the event, and are derived in~\cite{PhysRevD.63.042003}. The quantity $r_{1,i}$ is a fiducial distance at which detector $i$ would register SNR=1 for an optimally oriented binary (face\nobreakdashes-on, and in a direction perpendicular to the interferometer's arms),
%
\marginpar{I seem to have dropped a factor of 2 here...}%
%
\begin{equation}\label{eq:horizon}
r_{1,i} = 1 / \sigma_i, \qquad {\sigma_i}^2 = \int_0^\infty \frac{\left|h(\omega; \mathbf \theta)\right|^2}{S_i(\omega)} \,d\omega.
\end{equation}

More succinctly, we can write the signal received by detector $i$ in terms of observable extrinsic parameters $\bm\theta_i = (\rho_i, \gamma_i, \tau_i)$, the amplitude $\rho_i$, phase $\gamma_i$, and time delay $\tau_i$ on arrival at detector $i$,
%
\begin{equation}\label{eq:signal-model}
    x_i (\omega; \bm\theta_i, \bm\theta_\mathrm{in}) = x_i (\omega; \rho_i, \gamma_i, \tau_i, \bm\theta_\mathrm{in}) = \frac{\rho_i}{\sigma_i} e^{i (\gamma_i - \omega \tau_i)} h(\omega; \bm\theta_\mathrm{in}).
\end{equation}

The prevailing technique for detection of \acp{GW} from \acp{CBC} is to realize a \ac{MLE} from the likelihood in Equation~(\ref{eq:gaussian-likelihood}) and the signal model in Equation~(\ref{eq:signal-model}). Concretely, this results in a bank of matched filters, or the cross-correlation between a template waveform and the incoming data stream,
%
\begin{equation}
z_i(\tau_i;\bm\theta_\mathrm{in}) = \frac{1}{\sigma_i (\bm\theta_\mathrm{in})} \int_0^\infty \frac{h^*(\omega; \bm\theta_\mathrm{in}) y_i(\omega) e^{i \omega \tau_i}}{S_i(\omega)} \,d\omega.
\end{equation}
%
The \ac{ML} point estimates of the signal parameters, $\mathrm{MLE}(\mathbf{y}) = \{\{ \hat{\bm\theta}_i \}_i, \hat{\bm\theta}_\mathrm{in}\} = \{\left\{ \hat\rho_i, \hat\gamma_i, \hat\tau_i \right\}_i, \hat{\bm\theta}_\mathrm{in}\}$, are given by
%
\begin{eqnarray}
    \hat{\bm\theta}_\mathrm{in}, \{\hat\tau_i\}_i
        &=& \argmax_{\bm\theta_\mathrm{in}, \{\hat\tau_i\}_i}
        \sum_i \left| z_i\left(\tau_i;
        \bm\theta_\mathrm{in}\right) \right|^2, \\
    \hat\rho_i &=& \left| z_i\left(\hat\tau_i;
        \hat{\bm\theta}_\mathrm{in}\right) \right|, \\
    \hat\gamma_i &=& \arg z_i\left(\hat\tau_i;
        \hat{\bm\theta}_\mathrm{in}\right).
\end{eqnarray}
%
A detection candidate consists of $\{\left\{ \hat\rho_i, \hat\gamma_i, \hat\tau_i \right\}_i, \hat{\bm\theta}_\mathrm{in}\}$. There are various ways to characterize the significance of a detection candidate, but in Gaussian noise the combined SNR $\hat\rho_\mathrm{c}$ suffices,
%
\marginpar{What is the least that I can get away with saying about false alarm rate estimation and likelihood ratios?}%
%
\begin{equation}
    \hat\rho_\mathrm{c} = \sqrt{\sum_i {\hat\rho_i}^2}.
\end{equation}

\subsection{Bayesian probability and parameter estimation}

In the Bayesian framework, the parameters are inferred from the data by forming the posterior distribution, $p(\bm\theta|\mathbf y)$, which describes the probability of the parameters given the observations. Bayes' rule relates the likelihood $p(\mathbf y|\bm\theta)$ to the posterior $p(\bm\theta|\mathbf y)$,
%
\begin{equation}\label{bayes}
p(\bm\theta|\mathbf y) = \frac{p(\mathbf y|\bm\theta) p(\bm\theta)}{p(\mathbf y)},
\end{equation}
%
introducing the prior distribution $p(\bm\theta)$ which encapsulates previous information about the paramters (for example, arising from earlier observations or from known physical bounds on the parameters), and the evidence $p(\mathbf y)$ which can be thought of as a normalization factor or as describing the parsimoniousness of the model.

The choice of prior is open to one's astrophysical preconceptions, but during \ac{S6} when \ac{LIGO}'s Bayesian \ac{CBC} parameter estimation pipelines were pioneered, the prior was taken to be isotropic in sky location and binary orientation, and uniform in volume, arrival time, and the component masses~\cite{2013arXiv1304.1775T}.

In Bayesian inference, although it is often easy to write down the likelihood or even the full posterior in closed form, usually one is interested in only a subset $\bm\beta$ of all of the model's parameters, the others $\bm\lambda$ being nuisance parameters. In this case, we integrate away the nuisance parameters, forming the marginal posterior
%
\begin{equation}\label{eq:marginal-posterior}
    p(\bm\beta|\mathbf y) = \int \frac{p(\mathbf y|\bm\beta,\bm\lambda) p(\bm\beta,\bm\lambda)}{p(\mathbf y)} \,d\bm\lambda
\end{equation}
%
with $\bm\theta = (\bm\beta, \bm\lambda)$. For instance, for the purpose of locating a \ac{GW} source on the sky, all parameters but $(\alpha, \delta)$ are nuisance parameters.

Bayesian parameter estimation has many advantages, including broad generality and the ability to make probabilistically meaningful statements even with very low \ac{SNR} measurements. However, in problems of even modest complexity, the marginalization step involves many-dimensional, ill-behaved integrals. The powerful \ac{MCMC} integration technique has become almost synonymous with Bayesian inference. Though powerful, \ac{MCMC} is inherently non-deterministic and resistant to parallelization, as well as (at least historically) slow. With the most sophisticated \ac{CBC} parameter estimation codes, it still takes days to process a single event. This delay is undesirable for planning targeted \ac{EM} follow\nobreakdashes-up searches of \ac{LIGO} events.

In what follows, we propose a complementary rapid parameter estimation scheme that can produce reliable positions estimates within minutes of a detection. We can even use our scheme to speed up the full \ac{MCMC} analysis and make the refined parameter estimates available more quickly. The key difference is that we start not from the \ac{GW} signal itself, but from the point parameter estimates from the detection. By harnessing the detection pipeline in this manner, we arrive at a simpler Bayesian problem that is amenable to straightforward, deterministic, numerical quadrature.

\section{Measurement uncertainty}

For the purpose of rapid sky localization, we assume that we do not have access to the \ac{GW} data $\mathbf{y}$ itself, and that our only contact with it is through the ML parameter estimates $\{\left\{ \hat\rho_i, \hat\gamma_i, \hat\tau_i \right\}_i, \hat{\bm\theta}_\mathrm{in}\}$. Although this is a significant departure from conventional GW parameter estimation techniques, we can still apply the full Bayesian machinery of Equation~(\ref{eq:marginal-posterior}) to compute a posterior distribution for the sky location.

\marginpar{This paragraph might make more sense in a conclusion.}%
%
There are many practical advantages of doing so. For one, there are difficulties in synchronously gathering together the calibrated GW strain data, auxiliary instrument channels, and data quality vetoes from all of the sites. The data consumed by the real\nobreakdashes-time detection pipeline are not necessarily final. Longer\nobreakdashes-running follow\nobreakdashes-up analyses can benefit from offline calibration, whereas the rapid sky localization need not re\nobreakdashes-analyze the online data. Moreover, the dimensionality of the problem is greatly reduced, and the problem becomes computationally easier.

\subsection{Fisher matrix: single detector}

To treat the ML estimates as measurements in and of themselves, we need to work out their likelihood, marginalized over the GW signal $\mathbf{y}$,
%
\begin{equation}\label{eq:detection-candidate-likelihood}
    p\left(\{\hat{\bm\theta}_i\}_i,
        \hat{\bm\theta}_\mathrm{in}
    \middle| \bm\theta\right)
    \propto \int\limits_{\mathclap{\mathbf{y} | \mathrm{MLE}(\mathbf{y}) =
        \{\{\hat{\bm\theta}_i\}_i,
        \hat{\bm\theta}_\mathrm{in}\}}}
    p(\mathbf{y} | \bm\theta) \, p(\bm\theta)
    \, d\mathbf{y}
\end{equation}
%
The integral above could be written in terms of the matched filter signals $\left\{z_i\right\}_i$, such that $z_i\left(\hat\tau_i, \hat{\bm\theta}_\mathrm{in}\right) = \hat\rho_i e^{i \hat\gamma_i}$ and $\forall t$, $\left|z_i(t, \bm\theta_\mathrm{in})\right| \leq \hat\rho_i$. The combination of the nontrivial integration limits and the Fourier transform in the matched filter seem like a problem for direct evaluation.

However, even without directly evaluating the distribution of the \ac{ML} estimator, we know many of its properties. The \ac{CRLB} gives its covariance in the asymptotic limit of high \ac{SNR}. The \ac{CRLB} has been widely applied in \ac{GW} data analysis \cite{fairhurst:2009}. We will momentarily consider the likelihood for a single detector:
%
\begin{multline}\label{eq:gaussian-likelihood-spa}
    \mathcal{L}\left(y_i; \rho_i, \gamma_i, \tau_i,
        \bm\theta_\mathrm{in}\right) \\
    \propto \exp \left[
        - \frac{1}{2} \int_0^\infty \frac{\left|y_i (\omega)
            - x_i\left(y_i; \rho_i, \gamma_i, \tau_i,
                \bm\theta_\mathrm{in}\right)
        \right|^2}{S_i(\omega)} \, d\omega
    \right],
\end{multline}
%
with $x_i(\omega; \rho_i, \gamma_i, \tau_i, \bm\theta_\mathrm{in})$ given by Equation~(\ref{eq:signal-model}).

The Fisher information matrix for a measurement $y$ described by the unknown parameter vector $\bm{\theta}$ is
%
\begin{equation}\label{eq:general-fisher-matrix}
    \mathcal{I}_{jk} = \mathrm{E} \, \left[
        -\frac{\partial^2 \log
            \mathcal{L}(y_i ; \bm\theta)}
            {\partial \theta_j \theta_k}
    \middle| \bm\theta
    \right].
\end{equation}
%
In other words, it is the expectation value, condition on the true parameter values, of the Jacobian of the log likelihood. This equation involves double derivatives, but substantial simplification is possible when---as in this case---the likelihood is Gaussian:
%
\begin{equation}\label{eq:gaussian-fisher-matrix}
    \mathcal{I}_{jk} = \int_0^\infty \Re \left[
        \left(\frac{\partial x_i}{\partial \theta_j}\right)^*
        \left(\frac{\partial x_i}{\partial \theta_k}\right)
    \right] \frac{1}{S_i(\omega)} \, d\omega.
\end{equation}
%
This form is more useful because it involves only first derivatives, and of the signal $x_i (\omega)$ rather than the entire observation $y (\omega)$. In terms of the $k$th \ac{SNR}-weighted moment of angular frequency,
%
\begin{equation}\label{eq:angular-frequency-moments}
    {\overline{\omega^k}}_i =
        \left[ \int_0^\infty \frac{|h (\omega)|^2}{S_i(\omega)} \omega^k \, d\omega \right]
        \left[ \int_0^\infty \frac{|h (\omega)|^2}{S_i(\omega)} \, d\omega \right]^{-1},
\end{equation}
%
the Fisher matrix for the signal in the $i$th detector is
%
\begin{equation}
    \mathcal{I}_i = \left(
        \begin{array}{cc}
            \mathcal{I}_{\bm\theta_i,\bm\theta_i} &
            \mathcal{I}_{\bm\theta_i,\bm\theta_\mathrm{in}} \\
            {\mathcal{I}_{\bm\theta_i,\bm\theta_\mathrm{in}}}^\intercal &
            {\rho_i}^2 \mathcal{I}_{\bm\theta_\mathrm{in},\bm\theta_\mathrm{in}}
        \end{array}
    \right)
\end{equation}
%
where
%
\begin{equation}\label{eq:fisher-matrix}
    \mathcal{I}_{\bm\theta_i,\bm\theta_i} = \bordermatrix{
        ~ & \rho_i & \gamma_i & \tau_i \cr
        \rho_i & 1 & 0 & 0 \cr
        \gamma_i & 0 & {\rho_i}^2 & -{\rho_i}^2 {\overline{\omega}}_i \cr
        \tau_i & 0 & -{\rho_i}^2 {\overline{\omega}}_i & {\rho_i}^2 {\overline{\omega^2}}_i
    }.
\end{equation}
%
(See also \cite{Grover:2013}.) To lowest post\nobreakdashes-Newtonian order, the intrinsic parameters affect the phase evolution but not the amplitude evolution, so for BNS systems we can assume $\mathcal{I}_{\rho_i,\bm\theta_\mathrm{in}} \approx 0$.
%
\marginpar{Show this?}%
%
When we form the Fisher matrix for the whole network, if the detectors all have the same noise \acp{PSD}, $S_1(\omega) = S_2(\omega) = \cdots = S_n(\omega) \equiv S(\omega)$, then we can change variables from phases and times on arrival $\left\{\gamma_i, \tau_i\right\}_i$ to appropriate differences between them, in order to cancel out all off-diagonal terms between the intrinsic and extrinsic parameters. Because all existing ground-based GW detectors have similar bandpasses, we restrict all of our further attention to just the extrinsic part of the Fisher matrix, $\mathcal{I}_{\bm\theta_i,\bm\theta_i}$.

\subsection{\ac{CRLB} and physical interpretation}

If $\hat{\bm\theta}$ is an unbiased estimator of $\bm\theta$, $\tilde{\bm\theta} = \hat{\bm\theta} - \bm\theta$ is the measurement error, and $\Sigma = \mathrm{E} \, [\tilde{\bm\theta}\tilde{\bm\theta}^\intercal]$ is the covariance of the measurement error, then the \ac{CRLB} says that $\Sigma \geq \mathcal{I}^{-1}$, in the sense that $\left(\Sigma - \mathcal{I}^{-1}\right)$ is positive semi\nobreakdashes-definite. Specifically, for our likelihood, the \ac{CRLB} implies that
%
\begin{equation}\label{eq:covariance-matrix}
    \cov{
        \left(
        \begin{array}{c}
            \tilde{\rho}_i \\
            \tilde{\gamma}_i \\
            \tilde{\tau}_i
        \end{array}
        \right)
    } \geq \mathcal{I}^{-1} = \left(
        \begin{array}{ccc}
            1 & 0 & 0 \\
            0 & {\rho_i}^2 {\overline{\omega^2}}_i/{\omega_{\mathrm{rms},i}}^2 & {\rho_i}^2 {\overline{\omega}}_i/{\omega_{\mathrm{rms},i}}^2 \\
            0 & {\rho_i}^2 {\overline{\omega}}_i/{\omega_{\mathrm{rms},i}}^2 & {\rho_i}^2/{\omega_{\mathrm{rms},i}}^2
        \end{array}
    \right)
\end{equation}
%
where ${\omega_{\mathrm{rms},i}}^2 = {\overline{\omega^2}}_i - {{\overline{\omega}}_i}^2$. Reading off the $\tau \tau$ element of the covariance matrix reproduces the timing accuracy in Equation~(24) of \cite{fairhurst:2009},
%
\begin{equation}\label{eq:timing-crlb}
    \std \left(\hat{\tau}_i - \tau_i \right) \geq \sqrt{\left(\mathcal{I}^{-1}\right)_{\tau\tau}} = \frac{\rho_i}{\omega_{\mathrm{rms},i}}.
\end{equation}
%
Furthermore, the Fisher matrix in Equation~(\ref{eq:fisher-matrix}) is block diagonal, which implies that estimation errors in the signal amplitude $\rho$ are uncorrelated with the phase $\gamma$ and time $\tau$. A sequence of two changes of variables lends some physical interpretation to the nature of the coupled estimation errors in $\gamma$ and $\tau$.

First, we put the phase and time on the same footing by measuring the time in units of $1 / \sqrt{\overline{\omega^2}}$ with a change of variables from $\tau$ to $\gamma_\tau = \sqrt{\overline{\omega^2}} \tau$:
%
\begin{equation}
    \mathcal{I}' = \bordermatrix{
        ~ & \rho_i & \gamma_i & \gamma_{\tau,i} \cr
        \rho_i & 1 & 0 & 0 \cr
        \gamma_i & 0 & {\rho_i}^2 & -{\rho_i}^2\frac{{\overline{\omega}}_i}{\sqrt{{\overline{\omega^2}}_i}} \cr
        \gamma_{\tau,i} & 0 & -{\rho_i}^2\frac{{\overline{\omega}}_i}{\sqrt{{\overline{\omega^2}}_i}} & {\rho_i}^2
    }.
\end{equation}
%
The second change of variables, from $\gamma$ and $\gamma_\tau$ to $\gamma_\pm = \frac{1}{\sqrt{2}}(\gamma \pm \gamma_\tau)$, diagonalizes the Fisher matrix:
%
\begin{equation}\label{eq:fisher-matrix-extrinsic-one-detector}
    \mathcal{I}'' = \bordermatrix{
        ~ & \rho_i & \gamma_{+,i} & \gamma_{-,i} \cr
        \rho_i & 1 & 0 & 0 \cr
        \gamma_{+,i} & 0 & \left(1 - \frac{\overline{\omega}_i}{\sqrt{\overline{\omega^2}_i}}\right){\rho_i}^2 & 0 \cr
        \gamma_{-,i} & 0 & 0 & \left(1 + \frac{\overline{\omega}_i}{\sqrt{\overline{\omega^2}_i}}\right){\rho_i}^2
    }.
\end{equation}
%
Thus, in the appopriate time units, the \textit{sum and difference} of the phase and time of the signal are measured independently.

\section{The \ac{BAYESTAR} likelihood}

Although we may not be able to compute the detection candidate likelihood, Equation~(\ref{eq:detection-candidate-likelihood}), directly, we can make an educated guess that has many properties in common with it. Any valid approximate likelihood must have the same Fisher matrix Equation~(\ref{eq:fisher-matrix-extrinsic-one-detector}). It must also have the same limiting behavior: it should be periodic in the phase error $\tilde{\gamma}_i$ and go to zero as $\tilde{\tau}_i \rightarrow \pm \infty$, $\hat{\rho}_i \rightarrow 0$, or $\hat{\rho}_i \rightarrow \infty$. Additionally, when $\tilde{\tau}_i = 0$, the distribution of ${\hat{\rho}_i}^2$ should reduce to a noncentral $\chi^2$ distribution with two degrees of freedom, centered about ${\rho_i}^2$, because the complex matched filter time series $z_i(t)$ is Gaussian.

These conditions could be satisfied by realizing a multivariate Gaussian distribution with covariance matrix $\Sigma = \mathcal{I}^\intercal$, and then replacing individual terms of the form $-\tilde{\theta}^2/2$ with $\cos{\tilde{\theta}}$.

\marginpar{Actually, this does not give exactly the same Fisher matrix. Explain.}%
%
Another way is to plug the signal model from Equation~(\ref{eq:signal-model}) \emph{evaluated at the ML parameter estimates} into the single-detector likelihood in Equation~(\ref{eq:gaussian-likelihood-spa}):
%
\begin{widetext}
\begin{eqnarray*}
    p\left(\hat{\bm\theta}_i \middle| \bm\theta \right)
    &:=&
    p\left(y_i(\omega) = x_i(\omega; \hat{\bm\theta}_i)
        \middle| \bm\theta \right)
    \\
    &\propto& \exp \left[
        - \frac{1}{2} \int_0^\infty \frac{\left|
            \frac{\hat{\rho}_i}{\sigma_i(\hat{\bm\theta}_\mathrm{in})} e^{i (\hat\gamma_i - \omega \hat\tau_i)} h(\omega; \hat{\bm\theta}_\mathrm{in})
            - \frac{\rho_i}{\sigma_i(\bm\theta_\mathrm{in})} e^{i (\gamma_i - \omega \tau_i)} h(\omega; \bm\theta_\mathrm{in})
        \right|^2}{S_i(\omega)} \, d\omega
    \right].
\end{eqnarray*}
\end{widetext}
%
If we assume that $\hat{\bm\theta}_\mathrm{in} = \bm\theta_\mathrm{in}$, then this reduces to
%
\begin{equation}\label{eq:autocor-likelihood}
    p\left(\hat\rho_i, \hat\gamma_i, \hat\tau_i
        \middle| \rho_i, \gamma_i, \tau_i \right) \propto
    \exp \left[ - \frac{1}{2}{\hat\rho_i}^2 - \frac{1}{2}{\rho_i}^2
        + \hat\rho_i \rho_i \Re \left\{ e^{i \tilde{\gamma}_i} a_i^*(\tilde{\tau}_i)
        \right\}
    \right]
\end{equation}
%
with $\tilde{\gamma}_i = \hat\gamma_i - \gamma_i$, $\tilde{\tau}_i = \hat\tau_i - \tau_i$, and the template's autocorrelation function $a_i(t; \bm\theta_\mathrm{in})$ defined as
%
\begin{equation}\label{eq:autocorrelation-function}
    a_i(t; \bm\theta_\mathrm{in}) := \frac{1}{{{\sigma_i}^2(\bm\theta_\mathrm{in})}} \int_0^\infty \frac{\left| h(\omega; \hat{\bm\theta}_\mathrm{in})\right|^2}{S_i(\omega)} e^{i \omega t} \,d\omega.
\end{equation}

To assemble the joint likelihood for the whole network, we just form the product from the individual detectors:
%
\begin{multline}
    p\left(\left\{\hat\rho_i, \hat\gamma_i, \hat\tau_i\right\}_i
        \middle| \left\{\rho_i, \gamma_i, \tau_i\right\}_i \right) \\ \propto
    \exp \left[ - \frac{1}{2} \sum_i {\hat\rho_i}^2 - \frac{1}{2} \sum_i {\rho_i}^2
        + \sum_i \hat\rho_i \rho_i \Re \left\{ e^{i \tilde{\gamma}_i} a^*(\tilde{\tau}_i)
        \right\}
    \right].
\end{multline}

\subsection{Properties}

First, observe that at the true parameter values, $\hat{\bm\theta}_i = \bm\theta_i$, the logarithms of Equation~(\ref{eq:autocor-likelihood}) and Equation~(\ref{eq:gaussian-likelihood-spa}) have the same Jacobian. This is because the derivatives of the autocorrelation function are
%
\begin{equation*}
    a^{(n)}(t) = i^n \overline{\omega^n};
\end{equation*}
%
for instance,
%
\begin{equation*}
    a(0) = 1,
    \qquad
    a'(0) = i \overline{\omega},
    \qquad
    a''(0) = -\overline{\omega^2}.
\end{equation*}

We can compute the Fisher matrix elements for the autocorrelation likelihood given by Equation~(\ref{eq:autocor-likelihood}), with detector subscript suppressed:
%
\begin{eqnarray}
    \nonumber
    \mathcal{I}_{\rho\rho} &=& 1 \\
    \nonumber
    \mathcal{I}_{\rho\gamma} &=& 0 \\
    \nonumber
    \mathcal{I}_{\rho\tau} &=& 0 \\
    \label{eq:fisher-autocor-gamma-gamma}
    \mathcal{I}_{\gamma\gamma} &=& \rho^2
        \int_{-T}^T \left|a(t)\right|^2 w(t; \rho) dt \\
    \label{eq:fisher-autocor-tau-tau}
    \mathcal{I}_{\tau\tau} &=& -\rho^2
        \int_{-T}^T \Re\left[a^*(t) a''(t)\right] w(t; \rho) dt \\
    \label{eq:fisher-autocor-gamma-tau}
    \mathcal{I}_{\gamma\tau} &=& -\rho^2
        \int_{-T}^T \Im\left[a^*(t) a'(t)\right] w(t; \rho) dt \\
    \nonumber\textrm{where} && \\
    w(t; \rho) &=& \frac{
        \displaystyle
        \exp\left[\frac{\rho^2}{4}\left|a(t)\right|^2\right]
        \left(
        I_0\left[\frac{\rho^2}{4}\left|a(t)\right|^2\right] +
        I_1\left[\frac{\rho^2}{4}\left|a(t)\right|^2\right]
        \right)
    }{
        \displaystyle
        2 \int_{-T}^T
        \exp\left[\frac{\rho^2}{4}\left|a(t')\right|^2\right]
        I_0\left[\frac{\rho^2}{4}\left|a(t')\right|^2\right]
        dt'
    }.
\end{eqnarray}
%
The notation $I_k$ denotes a modified Bessel function of the first kind. Matrix elements that are not listed have values that are implied by the symmetry of the Fisher matrix. Note that the minus signs are correct but a little confusing: despite them, $\mathcal{I}_{\gamma\gamma}, \mathcal{I}_{\tau\tau} \geq 0$ and $\mathcal{I}_{\gamma\tau} \leq 0$. The time integration limits $[-T, T]$ constitute a flat prior on arrival time, the time coincidence window between detectors.

If we can show that the weighting function $w(t; \rho)$ approaches a Dirac delta function as $\rho \rightarrow \infty$, then the Fisher matrix for the autocorrelation likelihood approaches the Fisher matrix for the full GW data, Equation~(\ref{eq:fisher-matrix}), as $\rho \rightarrow \infty$. The Bessel functions asymptotically approach:
%
\begin{equation*}
    I_0(x), I_1(x) \rightarrow \frac{e^x}{\sqrt{2 \pi x}}
    \textrm{ as } x \rightarrow \infty.
\end{equation*}
%
For large $\rho$, the exponential dominates and we can write:
%
\begin{equation*}
    w(t; \rho) \rightarrow \frac{
        \displaystyle
        \exp\left[\frac{\rho^2}{2}|a(t)|^2\right]
    }{
        \displaystyle
        \int_{-T}^T \exp\left[\frac{\rho^2}{2}|a(t')|^2\right] dt'
    }
    \textrm{ as } \rho \rightarrow \infty.
\end{equation*}
%
The Taylor expansion of $|a(t)|^2$ is
%
\begin{equation*}
    |a(t)|^2 = 1 + \frac{1}{2} \left(\frac{\partial^2}{\partial t^2}|a(t)|^2 \Bigg|_{t=0}\right) t^2 + \mathcal{O}(t^4)
    = 1 - {\omega_\mathrm{rms}}^2 t^2 + \mathcal{O}(t^4).
\end{equation*}
%
Substituting, we find that $w(t; \rho)$ approaches a normalized Gaussian distribution:
%
\begin{equation*}
    w(t; \rho) \approx \frac{
        \displaystyle
        \exp\left[-\frac{1}{2} \rho^2 {\omega_\mathrm{rms}}^2 t^2\right]
    }{
        \displaystyle
        \int_{-T}^T \exp\left[-\frac{1}{2} \rho^2 {\omega_\mathrm{rms}}^2 (t')^2\right] dt'
    }.
\end{equation*}
%
And finally, because the Dirac delta function may be defined as the limit of a Gaussian, $w(t; \rho) \rightarrow \delta(t)$ as $\rho \rightarrow \infty$.

We can now write the Fisher matrix for the autocorrelation likelihood in a way that makes a comparison to the full signal model explicit. Define:
%
\begin{eqnarray*}
    \mathcal{I}_{\gamma\gamma} &=& \rho^2 \cdot \textproto{D}_{\gamma\gamma}(\rho) \\
    \mathcal{I}_{\tau\tau} &=& \rho^2 \overline{\omega^2} \cdot \textproto{D}_{\tau\tau}(\rho) \\
    \mathcal{I}_{\gamma\tau} &=& -\rho^2 \overline{\omega} \cdot \textproto{D}_{\gamma\tau}(\rho)
\end{eqnarray*}
%
Now, the $\textproto{D}_{ij}$ %
%
\marginpar{The Fish(er) factor. Go home, Leo.}%
%
contain the integrals from Equations~(\ref{eq:fisher-autocor-gamma-gamma}, \ref{eq:fisher-autocor-tau-tau}, \ref{eq:fisher-autocor-gamma-tau}) and encode the departure of the autocorrelation likelihood from the likelihood of the full data at low SNR. All of the $\textproto{D}_{ij}(\rho)$ are sigmoid-type functions that asymptotically approach 1 as $\rho \rightarrow \infty$. The transition SNR $\rho_\mathrm{crit}$ is largely the same for all three nontrivial matrix elements, and is determined by the time coincidence window $T$ and the signal bandwidth $\omega_\mathrm{rms}$.
%
\marginpar{The transition SNR is probably proportional to some power of $(\omega_\mathrm{rms} T)$.}

In the limit of large SNR, our interpretation is that the point estimates $(\hat\rho, \hat\gamma, \hat\tau)$ contain all of the information about the underlying extrinsic parameters.

On the other hand, in the low SNR limit, the diminishing value of $\textproto{D}_{ij}(\rho)$ reflects the fact that some information is lost when the full data $\mathbf{x}$ is discarded. Concretely, as the prior interval $T$ becomes large compared to 1/$\rho\omega_\mathrm{rms}$, the ML estimator becomes more and more prone to pick up a spurious noise fluctuation far from the true signal. Clearly, when the coincidence window $T$ is kept small as possible, more information is retained in the ML point estimates. Put another way, if $T$ is small, then the transition SNR $\rho_\mathrm{crit}$ is also small and fainter signals become useful for parameter estimation.

\begin{figure*}
    \begin{center}
        \includegraphics{crlb_tau}
        \includegraphics{crlb_gamma}
    \end{center}
    \caption{\label{fig:crlb-tau}\ac{CRLB} on root\nobreakdashes-mean square timing uncertainty, using the likelihood for the full GW data (Equation~\ref{eq:gaussian-likelihood-spa}; dashed diagonal line) or the autocorrelation likelihood (Equation~\ref{eq:autocor-likelihood}; solid lines) with a selection of arrival time priors.}
\end{figure*}

\begin{figure}
    \begin{center}
        \includegraphics{fishfactor}
    \end{center}
    \caption{\label{fig:fishfactor}Ratio between Fisher matrix elements (solid: $\mathcal{I}_{\gamma\gamma}$, dashed: $\mathcal{I}_{\gamma\tau}$, dotted: $\mathcal{I}_{\tau\tau}$) for the the autocorrelation likelihood and the full GW data. Colors correspond to different arrival time priors as in Figure~\ref{fig:crlb-tau}.}
\end{figure}

\section{The \ac{BAYESTAR} algorithm}

Here we describe the numerical implementation of \ac{BAYESTAR}.

\subsection{Prior and problem setup}

The detection pipeline supplies a candidate $\{\left\{ \hat\rho_i, \hat\gamma_i, \hat\tau_i \right\}_i, \hat{\bm\theta}_\mathrm{in}\}$, and discretely sampled noise \acp{PSD} $S_i(\omega_j)$ for all detectors. \marginpar{Discuss single-detector threshold here?}

We compute the GW signal for a source with intrinsic parameters equal to the detection pipeline's estimate, $h(\omega; \hat{\bm\theta}_\mathrm{in})$.
Then we find the SNR=1 horizon distance $r_{1,i}$ for each detector by numerically integrating Equation~(\ref{eq:horizon}).

We have no explicit prior on the intrinsic parameters; in our analysis they are fixed at their \ac{ML} estimates, $\hat{\bm\theta}_\mathrm{in}$.

The arrival time prior is connected to the origin of the detector coordinate system. Given the Earth-fixed coordinates of the detectors $\mathbf{n}_i$ and the arrival times $\tau_i$, we compute their averages weighted by the timing uncertainty formula:
%
\begin{equation*}
    \langle \mathbf{n} \rangle = \frac{
        \displaystyle
        \sum_i \frac{\mathbf{n}_i}
            {\left(\hat\rho_i \omega_{\mathrm{rms},i}\right)^2}
    }{
        \displaystyle
        \sum_i \frac{1}{\left(\hat\rho_i \omega_{\mathrm{rms},i}\right)^2}
    },
    \qquad
    \langle \hat\tau \rangle = \frac{
        \displaystyle
        \sum_i \frac{\hat\tau_i}
            {\left(\hat\rho_i \omega_{\mathrm{rms},i}\right)^2}
    }{
        \displaystyle
        \sum_i \frac{1}{\left(\hat\rho_i \omega_{\mathrm{rms},i}\right)^2}
    }.
\end{equation*}
%
Then, we subtract off these means:
%
\begin{equation*}
    \mathbf{n}_i \leftarrow \mathbf{n}_i - \langle \mathbf{n} \rangle,
    \qquad
    \hat\tau_i \leftarrow \hat\tau_i - \langle \hat\tau \rangle.
\end{equation*}
%
In these coordinates relative to the weighted detector array barycenter, the arrival time prior is uniform in $-T \leq t \leq T$, with $T = \max\limits_i |\mathbf{n}_i| / c + 5\,\textrm{ms}$.

The distance prior is a user-selected power of distance,
%
\begin{equation*}
    p(r) \propto \begin{cases}
        r^m & \text{if } r_\mathrm{min} < r < r_\mathrm{max} \\
        0 & \text{otherwise}
    \end{cases}
\end{equation*}
%
where $m=2$ for a prior that is uniform in volume, and $m=-1$ for a prior that is uniform in the logarithm of the distance. If a distance prior is not specified, the default is uniform in volume out to the maximum SNR=4 horizon distance:
%
\begin{equation*}
    m = 2,
    \qquad
    r_\mathrm{min} = 0,
    \qquad
    r_\mathrm{max} = \frac{1}{4} \max_i r_{1,i}.
\end{equation*}

Finally, the prior is uniform in $-1 \leq \cos\iota \leq 1$ and $0 \leq \psi < 2\pi$.

We compute the autocorrelation function for each detector from $t = 0$ to $t = T$ at intervals of $\Delta t = 1/f_s$, where $f_s$ is the smallest power of two that is greater than or equal to the Nyquist rate. Because BNS signals typically terminate at about 1500\,Hz, a typical value for $\Delta t$ is $(4096\,\textrm{Hz})^{-1}$. We use a pruned \ac{FFT} because for BNS systems, the GW signal remains in LIGO's sensitive band for $\sim$100\nobreakdashes--1000\,s, whereas $T \sim 10$\,ms.\footnote{See \url{http://www.fftw.org/pruned.html} for a discussion of methods for computing the first $K$ samples of an \ac{FFT} of length $N$.}

\subsection{Marginal posterior}

The marginal posterior as a function of sky location is
%
\begin{multline}
    f(\alpha, \delta) \propto
    \int_{0}^{\pi}
    \int_{-1}^{1}
    \int_{-T}^{T}
    \int_{r_\mathrm{min}}^{r_\mathrm{max}}
    \int_{0}^{2\pi} \\
    %
    \exp \left[ - \frac{1}{2} \sum_i {\rho_i}^2
        + \sum_i \hat\rho_i \rho_i \Re \left\{ e^{i \tilde{\gamma}_i}
        a^*(\tilde{\tau}_i)
        \right\}
    \right] \\
    r^m \, dt_\oplus \, d\phi_c dr \, d\cos{\iota} \, d\psi.
\end{multline}

To marginalize over the coalescence phase, we can insert an arbitrary nuisance phase $\eta$ by making the replacement $\tilde{\gamma}_i \rightarrow \tilde{\gamma}_i + \eta$. Then integrating over $\eta$ from $0$ to $2\pi$ and suppressing normalization factors, we get
%
\begin{multline}
    f(\alpha, \delta) \rightarrow
    \int_{0}^{\pi}
    \int_{-1}^{1}
    \int_{-T}^{T}
    \int_{r_\mathrm{min}}^{r_\mathrm{max}} \\
    %
    \exp \left[ - \frac{1}{2} \sum_i {\rho_i}^2 \right] I_0 \left[
            \left| \sum_i \hat\rho_i \rho_i e^{i \tilde{\gamma}_i} a_i^*(\tilde{\tau}_i)
            \right|
    \right] \\
    r^m dr dt_\oplus \, d\cos{\iota} \, d\psi.
\end{multline}

\subsubsection{Integral over angles and time}

The integrand is periodic in $\psi$, so simple Newton-Cotes quadrature over $\psi$ exhibits extremely rapid convergence. We therefore sample the posterior on a regular grid of 10 points from 0 to $\pi$.

The integral over $\cos\iota$ converges with just as rapidly with Gauss-Legendre quadrature, so we use a 10\nobreakdashes-point Gauss-Legendre rule for integration over $\cos\iota$.

We sample $t_\oplus$ regularly from $-T$ to $T$ at intervals of $\Delta t$. This is typically $\sim 2 (10\,\mathrm{ms})(4096\,\mathrm{Hz}) \approx 80$\,samples. We use Catmull\nobreakdashes-Rom cubic splines to interpolate the real and imaginary parts of the autocorrelation functions between samples.

\subsubsection{Integral over distance}

The innermost integral over $r$ is a little bit more challenging. The distance integrand has both a sharp maximum\nobreakdashes-likelihood peak and an extended power\nobreakdashes-law prior\nobreakdashes-dominated tail. At any values of the other parameters, either the peak or the tail might dominate. If the peak dominates, it may not be successfully resolved by any general\nobreakdashes-purpose fixed\nobreakdashes-order quadrature scheme. Any general adaptive integrator may take a long time to find the peak.

Let's say that we want to evaluate an integral
%
\begin{equation}\label{eq:importance-sampling-difficult-integral}
    \mathscr{F}(x_1, x_2) = \int_{x_1}^{x_2} f(x') dx'
\end{equation}
%
Suppose that this integral is resistant to direct application of standard quadrature techniques, but we have another function $g(x)$ that we can integrate analytically or at least numerically with relative ease,
%
\begin{equation}
    \mathscr{G}(x) = G(x) - G(x_0) = \int_{x_0}^x g(x') dx'.
\end{equation}
%
There is an \emph{ultimate}, though tautological, change of variables that makes it trivial to evaluate $\mathscr{G}(x)$,
%
\begin{equation}
    \mathscr{G}(x) = \int_0^{\mathrlap{\mathscr{G}(x)}} dG.
\end{equation}
%
If we apply the same change of variables to Equation~(\ref{eq:importance-sampling-difficult-integral}), we get
%
\begin{equation}\label{eq:importance-sampling}
    \mathscr{F}(x_1, x_2) = \int_{\mathscr{G}(x_1)}^{\mathscr{G}(x_2)} \frac{f(\mathscr{G}^{-1}(G))}{g(\mathscr{G}^{-1}(G))} dG.
\end{equation}
%
If $f(x)$ and $g(x)$ have sufficiently similar behavior, then their quotient $f/g$ will be better behaved than $f$ itself, and more amenable to any given quadrature technique. When the transformed integral Equation~(\ref{eq:importance-sampling}) is evaluated using Monte Carlo integration, this technique is referred to as importance sampling.

We use the same kind of change of variables with fixed\nobreakdashes-order Gaussian quadrature. We first find the approximate \ac{ML} distance $r_0$ using Equation~(\ref{eq:ml-distance}). If $r_0 < r_\mathrm{min}$ or $r_0 > r_\mathrm{max}$, then the ML peak lies outside of the limits of integration and the original integrand behaves like a low-order power law. In this case, we use 10\nobreakdashes-point Gaussian quadrature to evaluate Equation~(\ref{eq:distance-integral}).

If, on the other hand, $r_\mathrm{min} \leq r_0 \leq r_\mathrm{max}$, then the integrand contains a sharp peak that we can smooth out with importance sampling. We first re-scale the distance integral Equation~(\ref{eq:distance-integral}) so that the peak value of the integrand is $\sim 1$:
%
\begin{equation}
    \mathscr{F} = \exp\left(\frac{b^2}{4p^2}\right)
        {r_0}^m
        \int_{r_\mathrm{min}}^{r_\mathrm{max}}
        \exp\left[-\left(\frac{p}{r} - \frac{b}{2p}\right)^2\right]
        \left[\frac{r}{r_0}\right]^m
        dr.
\end{equation}
%
The importance sampling integrand $g(r)$ is
%
\begin{equation}
    g(r) = \exp\left[-\left(\frac{p}{r} - \frac{b}{2p}\right)^2\right]
        \frac{1}{r^2}
\end{equation}
%
with definite integral
%
\begin{equation}
    \mathscr{G}(r) = \frac{\sqrt{\pi}}{p}
        Q\left[\sqrt{2}\left(\frac{p}{r} - \frac{b}{2p}\right)\right]
\end{equation}
%
where $Q$ is the cumulative distribution function for the upper tail of the standard normal distribution,
%
\begin{equation}
    Q(x) = \int_x^\infty \frac{1}{\sqrt{2\pi}} \exp \left[-\frac{{x'}^2}{2}\right] dx'.
\end{equation}
%
Its inverse is
%
\begin{equation}
    \mathscr{G}^{-1}(G) = \left[\frac{1}{r_0} + \frac{1}{\sqrt{2}p}
    Q^{-1}\left(\frac{p G}{\sqrt{\pi}}\right)\right]^{-1}.
\end{equation}
%
The transformed integral is
%
\begin{equation}
    \mathscr{F} = \exp\left(\frac{b^2}{4p^2}\right)
        {r_0}^m
        \int_{\mathscr{G}(r_\mathrm{min})}^{\mathscr{G}(r_\mathrm{max})}
        \overline{I}_0\left[\frac{b}{r}\right]
        \left[\frac{r}{r_0}\right]^m r^2
        \Bigg|_{r = \mathscr{G}^{-1}(G)}
        dG.
\end{equation}
%
This integral is evaluated numerically with a 10\nobreakdashes-point Gauss-Legendre rule.

Last, there are a few special cases where Equation~(\ref{eq:distance-integral}) can be evaluated exactly. If $p^2=0$ (which implies $b = 0$), then the integral may be expressed in terms of logarithms. If $b = 0$ but $p^2 \neq 0$, then the integral may be expressed in terms of the exponential integral function,
%
\begin{equation}
    E_n(x) = \int_1^\infty \frac{\exp (-xt)}{t^n} dt.
\end{equation}

The distance integral, therefore, takes either one or ten function evaluations.

\subsection{Adaptive mesh refinement}

We have explained how we evaluate the marginal posterior at a given sky location. Now we must specify where we choose to evaluate it.

Our sampling of the sky is relies completely on the \acl{HEALPix} (\acs{HEALPix}), a special data structure designed for all\nobreakdashes-sky maps. \ac{HEALPix} divides the sky into equal\nobreakdashes-area pixels. There is a hierarchy of \ac{HEALPix} resolutions. A HEALPix resolution may be designated by its order $N$. The $N=0$th order or base tiling has 12 pixels. At every successive order, each tile is subdivided into four new tiles. A resolution may also be referred to by the number of subdivisions along each side of the base tiles, $N_\mathrm{side} = N^2$. There are $N^\mathrm{pix} = 12 {N_\mathrm{side}}^2$ pixels at any given resolution. The \ac{HEALPix} projection uniquely specifies the coordinates of the center of each pixel by providing a mapping from the resolution and pixel index $(N_\mathrm{side}, i_\mathrm{pix})$ to right ascension and declination $(\alpha, \delta)$.

We begin by evaluating the posterior probability density at the center of each of the $N_{\mathrm{pix},0} = 3072$ pixels of an $N_{\mathrm{side},0}=16$ \ac{HEALPix} grid. At this resolution, each pixel has an area of 13.4\,deg$^2$. We then rank the pixels by contained probability (assuming constant probability density within a pixel), and subdivide the most probable $N_{\mathrm{pix},0}/4$ pixels into $N_{\mathrm{pix},0}$ new pixels. We then evaluate the posterior again at the pixels that we subdivided, sort again, and repeat seven times, so that we have evaluated the posterior probability density a total of $8 N_{\mathrm{pix},0}$ times. On \emph{most} iterations, we descend one level deeper in \ac{HEALPix} resolution. The resulting map is a tree structure that consists of a mix of several resolutions. We traverse the tree and flatten it into the highest resolution represented. The highest possible resolution is $N_\mathrm{side}=2^{11}$, with an area of $\approx 10^{-3}$\,deg$^2$ per pixel.\footnote{Although the resulting sky map contains $N_\mathrm{pix} \approx 5\times10^6$ pixels, at most $\approx 2\times10^4$ pixels have distinct values. For the purpose of delivery to observers, therefore, the output is always \texttt{gzip}\nobreakdashes-compressed with a ratio of $\approx 250:1$.}

Within each iteration, all of the marginalization integrals may be evaluated in parallel. In our C language implementation, the inner loop over pixels is parallelized with OpenMP\footnote{http://openmp.org/}.

\section{Results}

\begin{figure}
    \begin{center}
        \includegraphics{pp}
    \end{center}
    \caption{\label{fig:pp}$P-P$ plot.}
\end{figure}

\begin{acknowledgements}
\marginpar{This URL is not specific enough.}Source code for \ac{BAYESTAR} is available on the \ac{LIGO} \acl{DASWG} web site at \url{http://www.lsc-group.phys.uwm.edu/daswg/projects/lalsuite.html}.

Some of the results in this paper have been derived using \ac{HEALPix} \cite{healpix}.

\ac{LIGO} was constructed by the California Institute of Technology and Massachusetts Institute of Technology with funding from the \ac{NSF} and operates under cooperative agreement PHY\nobreakdashes-0107417. Some results were produced on the NEMO computing cluster operated by the Center for Gravitation and Cosmology at University of Wisconsin\nobreakdashes--Milwaukee under \ac{NSF} Grants PHY\nobreakdashes-0923409 and PHY\nobreakdashes-0600953. This research is supported by the \ac{NSF} through a Graduate Research Fellowship to L.S. This paper has \ac{LIGO} Document Number \ac{LIGO}\nobreakdashes-PXXXXXXX\nobreakdashes-vX.
\end{acknowledgements}

\bibliography{apj-jour,bib/telescope,ms}

\end{document}
